---
title: "Regressão linear part 4"
author: "Thais Lovisi"
date: "2023-03-05"
output: html_document
---

## R setup
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
pacotes <- c("plotly","tidyverse","ggrepel","fastDummies","knitr","kableExtra",
             "splines","reshape2","PerformanceAnalytics","correlation","see",
             "ggraph","psych","nortest","rgl","car","ggside","tidyquant","olsrr",
             "jtools","ggstance","magick","cowplot","emojifont","beepr","Rcpp",
             "equatiomatic")

options(rgl.debug = TRUE)

if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){
  instalador <- pacotes[!pacotes %in% installed.packages()]
  for(i in 1:length(instalador)) {
    install.packages(instalador, dependencies = T)
    break()}
  sapply(pacotes, require, character = T) 
} else {
  sapply(pacotes, require, character = T) 
}

```


## DIAGNÓSTICO DE MULTICOLINEARIDADE EM MODELOS DE REGRESSÃO 


### Knowing my data

```{r}
load(file = "salarios.RData")
glimpse(salarios)
``` 

```{r}
summary(salarios)
```
### Studying the Correlations
```{r}
cor(salarios$rh1, salarios$econometria1)
```

```{r warning=FALSE}
install.packages("metan")
library(metan)
  corr_plot(salarios[2:8],
            shape.point = 21,
            col.point = "black",
            fill.point = "#FDE725FF",
            size.point = 2,
            alpha.point = 0.6,
            maxsize = 4,
            minsize = 2,
            smooth = TRUE,
            col.smooth = "black",
            col.sign = "cyan1",
            upper = "corr",
            lower = "scatter",
            diag.type = "density",
            col.diag = "aquamarine",
            pan.spacing = 0,
            lab.position = "bl")
``` 

```{r}
salarios %>% select(2:4) %>% 
  correlation(method = "pearson") %>%
  plot()
```

### Generating the Linear models and investigating Multicollinearity

##### Perfect Correlation Case

```{r}
model1 <- lm(formula = salario ~ econometria1+rh1, 
             data = salarios)
summary(model1)
```
<br>Note that for model1 we have as output for variable rh1 NA. This is an strong indicator that our variable rh1 is is **perfectly correlated** with other variable at the model, in this case econometria1. Let`s run a calculation to confirm. Quando isso ocorre a X2 não terá p seu beta estimado. Note que econom e rh1 tem a mesma significância na construção do modelo.

```{r}
cor(salarios$rh1, salarios$econometria1)
```
<br>As we suspect the pearson coeficient is 1, indicating a perfect correlation. If we want more details we can run the next line.
```{r}
chart.Correlation(salarios[3:4], histogram = TRUE, method = "pearson")
``` 
##### Imperfect Correlation Case
```{r}
model2 <- lm(formula = salario ~ econometria2+rh2, 
             data = salarios)
summary(model2)
``` 

<br> Is possible to observe that the two variables were not significant at the test F. In models with strong but imperfect correlation, 1 or more variables can display itself as not being statistically significant, or in extreme cases with inverse signal (- and +). Thus, is extremely import investigate the correlation.

```{r}
cor(salarios$rh2, salarios$econometria2)
```
```{r}
chart.Correlation(salarios[5:6], histogram = TRUE, method = "pearson")
```
<br> A high pearson coeficient is displayed here 0.9938. So, what should I do ? 
<br>Dig deeper at the diagnostic by calculating Toleance and/or VIF, we can do it with the function ols_vif_tol()

```{r}
ols_vif_tol(model2)
```

<br> Observe that the tolerance is very close to 0 and VIF very high 82.06. So we can confirm that there is multicollinearity between the variables rh2 and econetria2.

<br> ***In this case is necessary to choose the type of analyse to be conducted (multivariate or bivariate), and if the multivariate model construction is opted for, a concious choice of wich one of the two variables will be kept*** . If you are in doubt you can run 2 separated multivariate model each one with one of the vars.

##### No Correlation Case

```{r}
model3 <- lm(formula = salario ~ econometria3+rh3, 
             data = salarios)
summary(model3)
```
<br> Is possible to observe that rh3 is not significant. Would be it due the multicollinearity? 

```{r}
cor(salarios$rh3,salarios$econometria3)
```
```{r}
chart.Correlation(salarios[7:8], histogram = TRUE, method = "pearson")
```
<br> A weak negative correlation is displayed, however I`m not convinced yet. Let`s dig  deeper...

```{r}
ols_vif_tol(model3)
``` 

<br> Note that the tolerance is near to 1 and VIF near to 0. So it doesn`t looks like that there is a omission by multicolinearity at the model. 

## DIAGNÓSTICO DE HETEROCEDASTICIDADE EM MODELOS DE REGRESSÃO     

```{r}
load(file = "saeb_rend.RData")
glimpse(saeb_rend)
```

```{r}
summary(saeb_rend)
```
##### generating abs. frequency table
```{r}
table(saeb_rend$rede)
``` 
```{r}
table(saeb_rend$uf)
```
##### Chart saeb given based at rendimento

```{r}
ggplotly(
  ggplot(saeb_rend,aes(x = rendimento, y = saeb))+
    geom_point(color = "orchid1", size = 2)+
    geom_smooth(color = "grey40", size = 2, se = F, method = "lm", formula = saeb ~rendimento)+
  theme_modern()
  
)
  
```

If I wanna a chart saeb given based at rendimento with emphasis at the rede category type. Gráfico com vários linear fit de acordo com  a rede de ensino
```{r}
ggplotly(
  ggplot(saeb_rend, aes(x = rendimento, y = saeb, color = rede, shape = rede)) +
    geom_point(size = 1) +
    geom_smooth(method = "lm", formula = y ~ x, se = F) +
    xlab("rendimento") +
    ylab("saeb") +
    scale_colour_viridis_d() +
    theme_classic()
)
``` 

If I wanna a chart saeb given based at rendimento with emphasis at the uf category type
```{r}
ggplotly(
  ggplot(saeb_rend,aes(x = rendimento, y = saeb, color = uf, shape = uf))+
    geom_point(size = 1)+
    geom_smooth(color = "grey40", size = 2, se = F, method = "lm", formula = saeb ~rendimento)+
  theme_modern()
  
)
```

##### Generating the model Diagnosis of Heteroskedacity 

<br>**WARNING:** Mesmo que os resultados passem e necessario fazer shapiro-francia e diagn. de heteroced. Pode ser que heterocedasticidade ocorra devido a omissao de var omitida ou/e em funçao da forma funcional adotada.

```{r}
saeb_model <- lm(formula = saeb ~ rendimento, data = saeb_rend)
summary(saeb_model)
```

<br> The diagnosis is made by the test of Breusch-Pagan, in R the function ols_test_breusch_pagan(). The test hypotesis are:
<br>	H0: Homoscedasticity is present (the residuals are distributed with equal variance)
<br>	HA: Heteroscedasticity is present (the residuals are not distributed with equal variance)
<br>If the p-value of the test is less than a significancy level ( α = .05) then we reject the H0 and conclude that heteroscedasticity is present in the regression model.

<br> Note que a significancia estatistica com R2 baixo pode ser devido a dispersão de pontos muito alta.

```{r}
ols_test_breusch_pagan(saeb_model)
``` 
#### Dummy Transformation

```{r}
saeb_rend_dummy <- dummy_columns(.data = saeb_rend,
                                      select_columns = "uf",
                                      remove_selected_columns = T,
                                      remove_most_frequent_dummy = T
                                 )
head(saeb_rend_dummy) #checking the first 6 values
```

### REGRESSÃO MÚLTIPLA COM DUMMIES E DIAGNÓSTICO DE HETEROCEDASTICIDADE  

```{r}
# considers uf and rendimento
modelosaeb_dummies_uf <- lm(formula = saeb ~ . -municipio -codigo -escola -rede,
                            data = saeb_rend_dummy)
summary(modelosaeb_dummies_uf)
```

```{r}
ols_test_breusch_pagan(modelosaeb_dummies_uf)
```

##### Chart saeb given based at rendimento with emphasis at UF

```{r}

ggplotly(
  ggplot(saeb_rend, aes(x = rendimento, y = saeb, color = uf, shape = uf)) +
    geom_point(size = 1) +
    geom_smooth(method = "lm", formula = y ~ x, se = F) +
    xlab("rendimento") +
    ylab("saeb") +
    scale_colour_viridis_d() +
    theme_classic()
)

```

##### Non linear

```{r}
load(file = "planosaude.RData")
glimpse(planosaude)
```

```{r}
#Univariate stat.
summary(planosaude)
```

```{r}
# Show me categories
levels(factor(planosaude$plano))
```

```{r}
#Abs. Frequency table
table(planosaude$plano)
```
##### Correlations
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
planosaude %>%
corr_plot(
            shape.point = 21,
            col.point = "black",
            fill.point = "#FDE725FF",
            size.point = 2,
            alpha.point = 0.6,
            maxsize = 4,
            minsize = 2,
            smooth = TRUE,
            col.smooth = "black",
            col.sign = "lightpink2",
            upper = "corr",
            lower = "scatter",
            diag.type = "density",
            col.diag = "pink",
            pan.spacing = 0,
            lab.position = "bl")
```
##### Dummy Transf.
```{r}
planosaude_dummies <- dummy_columns(.data = planosaude,
                                    select_columns = "plano",
                                    remove_selected_columns = T,
                                    remove_most_frequent_dummy = T)

```


##### Multiple Linear regression
```{r}
modelo_planosaude <- lm(despmed ~ . - id, planosaude_dummies)
summary(modelo_planosaude)
```

##### Stepwise

```{r}
step_plan <- step(modelo_planosaude, k = 3.841459)
summary(step_plan)
```
<br> It removed idade and renda.

##### Residual's Adeherence to Norm.
```{r}
sf.test(step_plan$residuals)
```
<br>The Shapiro-Francia shows the Non Adeherence of the residuals to Normality because it is <0.05.

```{r}
planosaude %>%
  mutate(residuos = step_plan$residuals) %>%
  ggplot(aes(x = residuos)) +
  geom_histogram(aes(y = ..density..), 
                 color = "white", 
                 fill = "cyan3", 
                 bins = 15,
                 alpha = 0.6) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(step_plan$residuals),
                            sd = sd(step_plan$residuals)),
                size = 2, color = "grey30") +
  scale_color_manual(values = "grey50") +
  labs(x = "Resíduos",
       y = "Frequência") +
  theme_bw()
```
<br> At the histogram is not possible verify the non adeherence for this case. So lets run the Kernel density estimation (KDE). Forma não-paramétrica para estimar a função densidade de probabilidade de uma variável aleatória.

```{r}
planosaude_dummies %>%
  ggplot() +
  geom_density(aes(x = step_plan$residuals), fill = "cyan3") +
  labs(x = "Resíduos do Modelo Stepwise",
       y = "Densidade") +
  theme_bw()
```

##### DIAGNSIS DE HETEROkEDASTICITY

```{r}
ols_test_breusch_pagan(step_plan)
```

<br> The data base had shown heterokedasticity, thus probably we have omission of predictive vars. 
<br>H0 do teste: ausência de heterocedasticidade.
<br>H1 do teste: heterocedasticidade, ou seja, correlação entre resíduos e uma ou mais variáveis explicativas, o que indica omissão de variável relevante!

##### Add fitted values and residuals at the dataset
```{r}

planosaude_dummies$fitted_step <- step_plan$fitted.values
planosaude_dummies$residuos_step <- step_plan$residuals
```

```{r}
#Gráfico que relaciona resíduos e fitted values do modelo 'step_planosaude'
planosaude_dummies %>%
  ggplot() +
  geom_point(aes(x = fitted_step, y = residuos_step),
             color = "#55C667FF", size = 3) +
  labs(x = "Fitted Values do Modelo Stepwise",
       y = "Resíduos do Modelo Stepwise") +
  theme_bw()
```

##### Box-Cox Transformation

###### Lambda Transformation
```{r}
lambda_BC <- powerTransform(planosaude$despmed)
lambda_BC
```
###### Calc. Y*
```{r}
planosaude_dummies$bcdespmed <- (((planosaude$despmed ^ lambda_BC$lambda) - 1) / 
                                      lambda_BC$lambda)
planosaude_dummies %>%
  select(id, despmed, bcdespmed, everything()) %>%
  kable() %>%
  kable_styling(bootstrap_options = "striped", 
                full_width = F, 
                font_size = 14)
```
##### Estimates the New Model
```{r}
modelo_bc_planosaude <- lm(formula = bcdespmed ~ . -id -despmed -fitted_step
                           -residuos_step, 
                           data = planosaude_dummies)
#Extact Parameters
summary(modelo_bc_planosaude)
```
##### New Stepwise
```{r}
step_bc_planosaude <- step(modelo_bc_planosaude, k = 3.841459)
```

```{r}
summary(step_bc_planosaude)
```

##### Adeherence to the Normality
```{r}
sf.test(step_bc_planosaude$residuals) 
```
<br> Adeherence to the normality.

```{r}
#Plotando os novos resíduos do modelo step_bc_planosaude com curva normal teórica
planosaude_dummies %>%
  mutate(residuos = step_bc_planosaude$residuals) %>%
  ggplot(aes(x = residuos)) +
  geom_histogram(aes(y = ..density..), 
                 color = "white", 
                 fill = "yellow", 
                 bins = 15,
                 alpha = 0.6) +
  stat_function(fun = dnorm, 
                args = list(mean = mean(step_bc_planosaude$residuals),
                            sd = sd(step_bc_planosaude$residuals)),
                size = 2, color = "grey30") +
  scale_color_manual(values = "grey50") +
  labs(x = "Resíduos",
       y = "Frequência") +
  theme_bw()
```
##### Kernel density estimation (KDE)
```{r}
planosaude_dummies %>%
  ggplot() +
  geom_density(aes(x = step_bc_planosaude$residuals), fill = "gold") +
  labs(x = "Resíduos do Modelo Stepwise com Transformação de Box-Cox",
       y = "Densidade") +
  theme_bw()

```

```{r}
#Diagnóstico de Heterocedasticidade para o Modelo Stepwise com Box-Cox
ols_test_breusch_pagan(step_bc_planosaude)
```

```{r}
#Adicionando fitted values e resíduos do modelo 'step_bc_planosaude' no dataset 'planosaude_dummies'
planosaude_dummies$fitted_step_novo <- step_bc_planosaude$fitted.values
planosaude_dummies$residuos_step_novo <- step_bc_planosaude$residuals
planosaude_dummies %>%
  ggplot() +
  geom_point(aes(x = fitted_step_novo, y = residuos_step_novo),
             color = "#440154FF", size = 3) +
  labs(x = "Fitted Values do Modelo Stepwise com Transformação de Box-Cox",
       y = "Resíduos do Modelo Stepwise com Transformação de Box-Cox") +
  theme_bw()
```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
